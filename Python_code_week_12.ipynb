{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "595b7d70",
   "metadata": {},
   "source": [
    "## Bank Marketing Campaign\n",
    "## Specialization: Data Science\n",
    "## Data Glacier Virtual Internship\n",
    "### Presented by the Greeks\n",
    "### Galanakis Michalis, Konioris Aggelos, Moysiadis Giorgos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a512d8f2",
   "metadata": {},
   "source": [
    "#### At first, we import all the libraries that will be utilized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fc6627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier as kNN\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# for reproducibility\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab9756b",
   "metadata": {},
   "source": [
    "#### Before starting our model buliding analysis, we run the code from the previous assignment for handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe5e39da",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_additional_full = pd.read_csv(\"bank-additional-full.csv\", delimiter = ';')\n",
    "df = bank_additional_full \n",
    "df.replace('unknown', np.nan, inplace = True)\n",
    "df['loan'].fillna(df['loan'].value_counts().index[0], inplace = True)\n",
    "df['marital'].fillna(df['marital'].value_counts().index[0], inplace = True)\n",
    "df['default'].fillna(df['default'].value_counts().index[0], inplace = True)\n",
    "\n",
    "def na_randomfill(function):\n",
    "    na = pd.isnull(function)   \n",
    "    number_null = na.sum()        \n",
    "    if number_null == 0:\n",
    "        return function             \n",
    "    fill_values = function[~na].sample(n = number_null, replace = True, random_state = 0)\n",
    "    fill_values.index = function.index[na]\n",
    "    return function.fillna(fill_values)\n",
    "\n",
    "df = df.apply(na_randomfill)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09814f49",
   "metadata": {},
   "source": [
    "#### This step provides the transformation of the qualitative variables into quantitative, so we can use them in our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6f037e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  housing  loan  contact  month  \\\n",
       "0   56    3        1          0        0        0     0        1      6   \n",
       "1   57    7        1          3        0        0     0        1      6   \n",
       "2   37    7        1          3        0        1     0        1      6   \n",
       "3   40    0        1          1        0        0     0        1      6   \n",
       "4   56    7        1          3        0        0     1        1      6   \n",
       "\n",
       "   day_of_week  ...  campaign  pdays  previous  poutcome  emp.var.rate  \\\n",
       "0            1  ...         1    999         0         1           1.1   \n",
       "1            1  ...         1    999         0         1           1.1   \n",
       "2            1  ...         1    999         0         1           1.1   \n",
       "3            1  ...         1    999         0         1           1.1   \n",
       "4            1  ...         1    999         0         1           1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed  y  \n",
       "0          93.994          -36.4      4.857       5191.0  0  \n",
       "1          93.994          -36.4      4.857       5191.0  0  \n",
       "2          93.994          -36.4      4.857       5191.0  0  \n",
       "3          93.994          -36.4      4.857       5191.0  0  \n",
       "4          93.994          -36.4      4.857       5191.0  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_column = df.dtypes[df.dtypes == 'object'].index\n",
    "\n",
    "labelencoder_X = LabelEncoder()\n",
    "for column in obj_column:\n",
    "    df[column] = labelencoder_X.fit_transform(df[column])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77a1f48",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction - You can think of this method as taking many features and combining similar or redundant features together to form a new, smaller feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e9cd078",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 3)\n",
    "pca_feats = pca.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9887946",
   "metadata": {},
   "source": [
    "#### After creating and transforming our features we are going to see which are the ones that PCA saw that are the principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c0e9b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PC1</td>\n",
       "      <td>duration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PC2</td>\n",
       "      <td>pdays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PC3</td>\n",
       "      <td>nr.employed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0            1\n",
       "0  PC1     duration\n",
       "1  PC2        pdays\n",
       "2  PC3  nr.employed"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_pcs = pca.components_.shape[0]\n",
    "most_important = [np.abs(pca.components_[i]).argmax() for i in range(n_pcs)]\n",
    "\n",
    "initial_feature_names = list(df.columns.values)\n",
    "\n",
    "most_important_names = [initial_feature_names[most_important[i]] for i in range(n_pcs)]\n",
    "dic = {'PC{}'.format(i + 1): most_important_names[i] for i in range(n_pcs)}\n",
    "pc_df = pd.DataFrame(sorted(dic.items()))\n",
    "pc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb8ec1d",
   "metadata": {},
   "source": [
    "#### Split our data in to train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35aec608",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('y', axis = 1), df['y'], test_size = .2, \n",
    "                                                    random_state = SEED, stratify = df['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3476d2",
   "metadata": {},
   "source": [
    "#### Rescale our data from their default range to 0-1 range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cd62f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a53c33d",
   "metadata": {},
   "source": [
    "# Model building and training\n",
    "#### Classification Models\n",
    "\n",
    "- Logistic Regression : model using logistic function to predict the result\n",
    "- Decision Tree Classifier : model using series decision nodes to predict the result\n",
    "- Random Forest Classifier : model using multiple decision tree classifier to predict the result\n",
    "- Support Vector Classifer : model using vectors to predict the result\n",
    "- Gradient Boosting Classifier : model using sequence of sub-models to sequentially correct predecessor's error and improve its performance\n",
    "- KNearest Classifier : model using nearest datapoints to predict the result\n",
    "\n",
    "#### Training the classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e3627ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LogisticRegression(random_state = SEED),\n",
    "          DecisionTreeClassifier(random_state = SEED),\n",
    "          RandomForestClassifier(random_state = SEED),\n",
    "          SVC(random_state = SEED),\n",
    "          XGBClassifier(verbosity = 0, random_state = SEED),\n",
    "          kNN()]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model in models:\n",
    "    fit = model.fit(X_train, y_train)\n",
    "    test_pred = fit.predict(X_test)\n",
    "    results[fit.__class__.__name__] = [\n",
    "        round(fit.score(X_test, y_test), 2),\n",
    "        round(f1_score(y_test, test_pred), 2),\n",
    "        round(cross_val_score(model, X_test, y_test, cv = 5).mean(), 2),\n",
    "        round(recall_score(y_test, test_pred), 2),\n",
    "        confusion_matrix(y_test, test_pred)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b205c2",
   "metadata": {},
   "source": [
    "#### Finally, we made a data frame with the outcomes along with the confusion matrixs of each mdodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "744c66db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>SVC</th>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_val_score</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[7132, 178], [575, 353]]</td>\n",
       "      <td>[[6860, 450], [444, 484]]</td>\n",
       "      <td>[[7055, 255], [460, 468]]</td>\n",
       "      <td>[[7204, 106], [711, 217]]</td>\n",
       "      <td>[[7018, 292], [422, 506]]</td>\n",
       "      <td>[[7077, 233], [669, 259]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         LogisticRegression     DecisionTreeClassifier  \\\n",
       "accuracy                               0.91                       0.89   \n",
       "f1_score                               0.48                       0.52   \n",
       "cross_val_score                        0.91                       0.89   \n",
       "recall                                 0.38                       0.52   \n",
       "confusion_matrix  [[7132, 178], [575, 353]]  [[6860, 450], [444, 484]]   \n",
       "\n",
       "                     RandomForestClassifier                        SVC  \\\n",
       "accuracy                               0.91                        0.9   \n",
       "f1_score                               0.57                       0.35   \n",
       "cross_val_score                        0.91                        0.9   \n",
       "recall                                  0.5                       0.23   \n",
       "confusion_matrix  [[7055, 255], [460, 468]]  [[7204, 106], [711, 217]]   \n",
       "\n",
       "                              XGBClassifier       KNeighborsClassifier  \n",
       "accuracy                               0.91                       0.89  \n",
       "f1_score                               0.59                       0.36  \n",
       "cross_val_score                        0.91                       0.89  \n",
       "recall                                 0.55                       0.28  \n",
       "confusion_matrix  [[7018, 292], [422, 506]]  [[7077, 233], [669, 259]]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = ['accuracy', 'f1_score', 'cross_val_score', 'recall', 'confusion_matrix']\n",
    "results_df = pd.DataFrame(data = results, index = index, columns = list(results.keys()))\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccd1298",
   "metadata": {},
   "source": [
    "#### With f1_score, we calculate a measure between precision and recall, where an F1 score reaches its best value at 1 and worst score at 0\n",
    "#### With cross_val_score, we evalute the score by cross-validation  \n",
    "#### With recall, we calculate the true positive rate was found by the model. The formula is: recall = tp/(tp+fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
